{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+Po776SGz7EIoZrkjtHYY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvvvvvss/Decision-Tree-based-ID3-Algorithm/blob/main/winequality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2HzDlajjuIrM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "data = pd.read_csv(url, sep=';')\n"
      ],
      "metadata": {
        "id": "FHWxAPpoEL25"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7vRw2XTEc0F",
        "outputId": "4c161276-4cf5-401f-bc01-d6df9f388f21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('quality', axis=1)\n",
        "y = data['quality']"
      ],
      "metadata": {
        "id": "W0gQ9qk7EhVz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y):\n",
        "  #entropy = -(p(+)log2p(+) + (p(-)log2p(-))\n",
        "    count=np.bincount(y)\n",
        "    p=count/len(y)\n",
        "    return -np.sum(p*np.log2(p))"
      ],
      "metadata": {
        "id": "BoYtR9zGhgDK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(X,y, feature_index):\n",
        "  #I.G = total Entropy - weighted avg entropy\n",
        "  total_entropy = entropy(y)\n",
        "  values, count=np.unique(X[:,feature_index], return_counts=True)\n",
        "  weighted_avg_entropy = np.sum((count[i] / np.sum(count)) * entropy(y[X[:, feature_index] == values[i]]) for i in range(len(values)))\n",
        "  return total_entropy - weighted_avg_entropy"
      ],
      "metadata": {
        "id": "QEtmxCYDi9nF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id3(X, y, feature_indices):\n",
        "    if len(np.unique(y)) == 1:\n",
        "        return y[0] if y.size > 0 else None\n",
        "\n",
        "    if len(feature_indices) == 0:\n",
        "        return np.bincount(y).argmax() if len(y) > 0 else None\n",
        "\n",
        "    if len(y) == 0:\n",
        "        return None\n",
        "\n",
        "    gains = [information_gain(X, y, i) for i in feature_indices]\n",
        "\n",
        "    if not gains:\n",
        "        return np.bincount(y).argmax() if len(y) > 0 else None\n",
        "\n",
        "    best_feature_index = feature_indices[np.argmax(gains)]\n",
        "\n",
        "    tree = {best_feature_index: {}}\n",
        "\n",
        "    feature_values = np.unique(X[:, best_feature_index])\n",
        "    for value in feature_values:\n",
        "        sub_X = X[X[:, best_feature_index] == value]\n",
        "        sub_y = y[X[:, best_feature_index] == value]\n",
        "        sub_feature_indices = [i for i in feature_indices if i != best_feature_index]\n",
        "        subtree = id3(sub_X, sub_y, sub_feature_indices)\n",
        "        tree[best_feature_index][value] = subtree\n",
        "\n",
        "    return tree"
      ],
      "metadata": {
        "id": "H9UcqwsH3Aly"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_np = X.to_numpy()\n",
        "y_np = y.to_numpy()"
      ],
      "metadata": {
        "id": "6O4uyHGbP7Aq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_indices = list(range(X_np.shape[1]))"
      ],
      "metadata": {
        "id": "kU1JcFRB3KuC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = id3(X_np, y_np, feature_indices)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mjDvvWxFOtx",
        "outputId": "cf223c58-b483-4101-e8fe-11e2899020a5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-07167b9b838a>:5: RuntimeWarning: divide by zero encountered in log2\n",
            "  return -np.sum(p*np.log2(p))\n",
            "<ipython-input-6-07167b9b838a>:5: RuntimeWarning: invalid value encountered in multiply\n",
            "  return -np.sum(p*np.log2(p))\n",
            "<ipython-input-33-d423d8b12dd8>:5: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  weighted_avg_entropy = np.sum((count[i] / np.sum(count)) * entropy(y[X[:, feature_index] == values[i]]) for i in range(len(values)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: {4.6: 4, 4.7: 6, 4.9: 7, 5.0: {1: {0.38: 6, 0.4: 6, 0.42: 8, 0.74: 6, 1.02: 4, 1.04: 5}}, 5.1: {1: {0.42: 7, 0.47: 6, 0.51: 7, 0.585: 7}}, 5.2: {1: {0.32: 5, 0.34: 6, 0.48: 7, 0.49: 6, 0.645: 6}}, 5.3: {1: {0.47: 7, 0.57: 7, 0.715: 5}}, 5.4: {1: {0.42: 7, 0.58: 6, 0.74: 6, 0.835: 7}}, 5.5: 8, 5.6: {1: {0.31: {2: {0.37: 5, 0.78: 6}}, 0.5: 5, 0.54: 5, 0.605: 5, 0.615: 5, 0.62: 4, 0.66: {2: {0.0: {3: {2.2: 7, 2.5: 5}}}}, 0.85: 8, 0.915: 5}}, 5.7: {1: {0.6: 6, 1.13: 4}}, 5.8: {1: {0.29: 6, 0.61: 6, 0.68: 5, 1.01: 6}}, 5.9: {1: {0.19: 5, 0.29: 6, 0.395: 6, 0.44: 6, 0.46: 5, 0.55: 6, 0.61: 6, 0.645: 5}}, 6.0: {1: {0.31: 6, 0.33: 4, 0.42: 6, 0.49: 6, 0.5: 5, 0.51: 6, 0.54: 6, 0.58: 6, 0.64: 5}}, 6.1: {1: {0.21: 6, 0.32: 5, 0.34: 5, 0.38: 5, 0.4: 7, 0.48: 6, 0.53: 6, 0.56: 6, 0.58: 6, 0.59: 5, 0.6: 5, 0.64: 5, 0.705: 5, 0.715: 5}}, 6.2: {1: {0.36: 6, 0.39: 7, 0.43: 6, 0.44: 6, 0.45: 5, 0.46: 5, 0.51: 6, 0.52: 6, 0.56: 5, 0.57: 6, 0.58: 5, 0.6: 5, 0.63: 5, 0.64: 5, 0.65: 5, 0.7: 6, 0.785: 4}}, 6.3: {1: {0.3: 6, 0.36: 6, 0.39: 5, 0.47: 6, 0.51: 6, 0.55: 6, 0.57: 5, 0.6: 5, 0.68: 6, 0.76: 6, 0.98: 6, 1.02: 4}}, 6.4: {1: {0.31: 7, 0.36: 6, 0.37: 6, 0.38: 6, 0.39: 6, 0.4: 5, 0.42: 6, 0.47: 6, 0.53: 4, 0.56: 6, 0.57: {2: {0.02: 5, 0.12: 7, 0.14: 5}}, 0.63: 5, 0.64: 5, 0.67: 6, 0.69: 6, 0.79: 6, 0.795: 5, 0.865: 6, 0.885: 5}}, 6.5: {1: {0.34: 6, 0.39: 6, 0.4: 6, 0.46: 5, 0.51: 6, 0.52: 5, 0.53: 6, 0.58: 4, 0.61: 6, 0.615: 5, 0.63: 6, 0.67: 4, 0.88: 4, 0.885: 5, 0.9: 6}}, 6.6: {1: {0.39: 6, 0.44: {2: {0.09: 6, 0.15: 5}}, 0.5: 6, 0.52: {2: {0.04: 6, 0.08: 7}}, 0.56: 7, 0.57: 5, 0.58: {2: {0.0: 6, 0.02: {3: {2.0: 7, 2.4: 6}}}}, 0.61: {2: {0.0: 4, 0.01: 5}}, 0.63: 5, 0.64: 5, 0.66: 5, 0.695: 5, 0.7: 5, 0.705: 5, 0.725: {2: {0.09: 6, 0.2: 5}}, 0.735: 5, 0.8: 5, 0.815: 7, 0.84: 7, 0.855: 6, 0.88: 5, 0.895: 6, 0.96: 6}}, 6.7: {1: {0.16: 6, 0.28: 7, 0.32: 7, 0.41: 6, 0.42: 6, 0.46: 6, 0.48: 5, 0.54: 5, 0.56: 5, 0.58: 5, 0.62: 6, 0.64: 5, 0.67: 6, 0.675: 5, 0.7: 5, 0.75: {2: {0.01: 6, 0.12: 5}}, 0.76: 3, 0.855: 6, 0.86: 6, 1.04: 4}}, 6.8: {1: {0.36: 7, 0.41: 6, 0.47: 6, 0.48: 5, 0.49: 6, 0.5: 5, 0.51: 6, 0.56: 6, 0.57: 6, 0.59: {2: {0.06: 7, 0.1: 5}}, 0.6: 6, 0.61: 5, 0.62: 6, 0.63: {2: {0.07: 6, 0.12: 5}}, 0.64: {2: {0.0: 6, 0.03: 6, 0.1: 5}}, 0.65: 6, 0.66: 5, 0.67: {2: {0.0: 5, 0.02: 5, 0.15: 6}}, 0.68: {2: {0.09: 4, 0.21: 5}}, 0.69: 5, 0.77: 5, 0.775: 5, 0.785: 6, 0.81: 6, 0.815: 3, 0.83: 5, 0.91: 4, 0.915: 5}}, 6.9: {1: {0.36: 6, 0.39: 4, 0.4: {2: {0.14: 6, 0.24: 5}}, 0.41: 6, 0.44: 6, 0.45: 6, 0.48: 4, 0.49: 6, 0.5: 5, 0.51: 6, 0.52: 5, 0.54: 6, 0.55: 5, 0.56: 5, 0.57: 5, 0.58: 5, 0.605: 6, 0.63: {2: {0.01: 6, 0.02: 5, 0.33: 5}}, 0.635: 6, 0.67: 5, 0.685: 6, 0.74: 6, 0.765: {2: {0.02: 5, 0.18: 6}}, 0.84: 6, 1.09: 4}}, 7.0: {1: {0.22: 6, 0.23: 5, 0.36: 6, 0.38: 6, 0.4: 7, 0.42: 5, 0.43: 6, 0.45: 5, 0.49: 5, 0.5: 5, 0.51: 5, 0.54: 6, 0.55: 6, 0.56: {2: {0.13: 5, 0.17: 7}}, 0.57: {2: {0.0: 6, 0.02: 5}}, 0.58: {2: {0.12: 5, 0.28: 6}}, 0.59: 5, 0.6: {2: {0.12: 7, 0.3: 5}}, 0.62: 5, 0.64: 6, 0.65: 6, 0.655: 5, 0.685: 5, 0.69: 6, 0.735: 5, 0.745: 6, 0.78: 5, 0.805: 5, 0.975: 4}}, 7.1: {1: {0.16: 6, 0.22: 6, 0.27: 6, 0.31: 5, 0.34: 5, 0.35: 6, 0.36: 5, 0.39: 6, 0.43: 5, 0.46: {2: {0.14: 5, 0.2: 6}}, 0.47: 4, 0.48: 5, 0.52: 5, 0.53: 6, 0.56: 5, 0.59: {2: {0.0: {3: {2.1: 7, 2.2: 6}}, 0.01: {3: {2.3: 6, 2.5: 5}}, 0.02: 6}}, 0.6: 6, 0.61: 6, 0.62: 5, 0.63: 5, 0.65: 5, 0.66: {2: {0.0: {3: {2.4: 7, 3.9: 5}}}}, 0.67: 5, 0.68: 5, 0.685: 5, 0.69: {2: {0.04: 5, 0.08: 6}}, 0.71: 5, 0.715: 5, 0.72: 5, 0.735: 5, 0.75: 6, 0.755: 5, 0.84: 4, 0.875: 3}}, 7.2: {1: {0.25: 7, 0.33: 8, 0.34: {2: {0.21: 6, 0.24: 5, 0.32: 5}}, 0.35: 6, 0.36: 7, 0.37: 7, 0.38: {2: {0.3: 6, 0.31: 8, 0.38: 7}}, 0.39: {2: {0.32: 5, 0.44: 6}}, 0.41: 5, 0.415: 5, 0.45: 6, 0.48: 7, 0.49: {2: {0.18: 6, 0.24: 5}}, 0.5: 6, 0.52: 6, 0.53: 6, 0.54: 5, 0.56: 5, 0.57: 6, 0.58: {2: {0.03: 5, 0.54: 4}}, 0.6: 5, 0.605: 6, 0.61: 5, 0.62: {2: {0.01: 6, 0.06: 5}}, 0.63: 6, 0.635: 5, 0.645: 6, 0.65: 5, 0.655: 5, 0.66: {2: {0.03: 5, 0.33: 6}}, 0.67: 6, 0.695: 5, 0.725: 5, 0.73: 5, 0.835: 5, 1.0: 5}}, 7.3: {1: {0.305: 6, 0.32: 5, 0.33: 6, 0.34: 7, 0.35: 4, 0.365: 5, 0.38: 5, 0.39: 6, 0.4: 6, 0.43: 6, 0.44: 6, 0.45: 5, 0.48: 7, 0.49: 5, 0.51: 6, 0.52: 6, 0.55: {2: {0.01: 7, 0.03: 4}}, 0.58: 5, 0.585: 5, 0.59: 5, 0.65: 7, 0.66: 6, 0.67: {2: {0.02: 6, 0.05: 5, 0.26: 5}}, 0.69: 5, 0.695: 5, 0.73: 5, 0.735: 5, 0.74: 5, 0.835: 5, 0.91: 5, 0.98: 3, 1.07: 5}}, 7.4: {1: {0.25: 7, 0.29: 6, 0.35: 6, 0.36: {2: {0.29: 5, 0.3: 8, 0.34: 7}}, 0.37: 6, 0.39: 5, 0.41: 5, 0.47: 5, 0.49: {2: {0.19: 5, 0.27: 6}}, 0.5: 5, 0.52: 6, 0.53: 5, 0.55: 5, 0.58: 6, 0.59: 4, 0.6: {2: {0.26: {3: {2.1: 6, 7.3: 5}}}}, 0.61: 5, 0.62: 6, 0.63: 6, 0.635: 7, 0.64: 5, 0.66: 5, 0.67: 5, 0.68: 6, 0.7: 5, 0.74: 5, 0.785: 6, 0.965: 5, 1.185: 3}}, 7.5: {1: {0.27: 7, 0.31: 6, 0.38: {2: {0.48: 4, 0.57: 6}}, 0.4: {2: {0.12: 6, 0.18: 5}}, 0.41: 5, 0.42: 5, 0.43: 7, 0.49: {2: {0.19: 5, 0.2: 6}}, 0.5: 5, 0.51: 6, 0.52: {2: {0.11: 5, 0.16: 7, 0.4: 6, 0.42: 6}}, 0.53: 6, 0.55: 6, 0.57: 6, 0.58: {2: {0.03: 5, 0.14: 5, 0.2: 5, 0.56: 6}}, 0.59: 5, 0.6: 5, 0.61: 5, 0.63: {2: {0.12: 5, 0.27: 6}}, 0.64: 6, 0.65: 5, 0.685: 4, 0.705: 5, 0.71: 6, 0.725: 5, 0.755: 4, 0.77: 5, 1.115: 4}}, 7.6: {1: {0.29: 6, 0.3: 6, 0.31: 7, 0.35: 6, 0.36: 6, 0.39: 5, 0.4: 6, 0.41: {2: {0.14: 6, 0.24: 5, 0.33: 5, 0.49: 5}}, 0.42: 5, 0.43: {2: {0.29: 5, 0.31: 6, 0.4: 6}}, 0.46: 5, 0.48: 6, 0.49: 5, 0.5: 6, 0.51: 6, 0.52: 5, 0.54: {2: {0.02: 6, 0.13: 5}}, 0.55: 5, 0.62: 5, 0.63: 6, 0.645: 5, 0.665: 5, 0.68: 4, 0.685: 5, 0.715: 6, 0.735: 7, 0.74: 5, 0.78: 6, 0.79: 5, 0.9: 5, 0.95: 5, 1.58: 3}}, 7.7: {1: {0.18: 6, 0.23: 6, 0.26: 6, 0.27: 7, 0.28: 7, 0.39: 5, 0.41: 5, 0.43: 6, 0.49: 5, 0.51: 5, 0.53: 6, 0.54: 5, 0.56: {2: {0.08: 6, 0.2: 5}}, 0.57: 6, 0.58: {2: {0.01: 7, 0.1: 6}}, 0.6: {2: {0.0: 5, 0.06: 6}}, 0.61: 6, 0.62: 5, 0.63: 6, 0.64: 5, 0.66: 5, 0.665: 5, 0.67: 5, 0.69: 5, 0.705: 5, 0.715: 6, 0.75: 5, 0.775: 5, 0.835: 5, 0.915: 7, 0.935: 5, 0.96: 5, 0.965: 5, 1.005: 5}}, 7.8: {1: {0.32: 7, 0.34: 6, 0.39: 6, 0.41: 5, 0.43: 5, 0.44: 5, 0.46: 6, 0.48: 6, 0.5: {2: {0.09: 5, 0.12: 6, 0.17: 5, 0.3: 6}}, 0.52: 6, 0.53: {2: {0.01: 5, 0.04: 6, 0.33: 5}}, 0.54: 6, 0.545: 6, 0.55: {2: {0.0: 6, 0.35: 5}}, 0.56: {2: {0.12: 6, 0.19: 5}}, 0.57: {2: {0.09: 8, 0.31: 5}}, 0.58: {2: {0.02: 7, 0.13: 6}}, 0.59: 5, 0.6: {2: {0.14: 6, 0.26: 5}}, 0.61: 5, 0.62: 5, 0.63: 5, 0.64: {2: {0.0: 5, 0.1: 7}}, 0.645: 6, 0.7: 5, 0.735: 6, 0.76: 5, 0.815: 5, 0.82: 5, 0.87: 5, 0.88: 5, 0.91: 6}}, 7.9: {1: {0.18: 5, 0.19: 6, 0.2: 7, 0.24: 6, 0.29: 6, 0.3: 7, 0.31: 6, 0.32: 6, 0.33: {2: {0.23: 5, 0.41: 6}}, 0.34: {2: {0.36: 7, 0.42: 6}}, 0.35: {2: {0.21: 5, 0.46: 8}}, 0.37: 5, 0.4: 6, 0.43: 5, 0.49: 5, 0.5: 5, 0.51: 6, 0.52: 5, 0.53: 6, 0.54: 8, 0.545: 6, 0.57: 6, 0.58: 6, 0.6: 5, 0.65: 7, 0.66: 5, 0.69: 5, 0.72: 5, 0.765: 6, 0.885: 4, 1.04: 6}}, 8.0: {1: {0.18: 6, 0.25: 6, 0.28: 5, 0.3: 6, 0.31: 7, 0.33: 6, 0.38: 6, 0.39: 5, 0.42: {2: {0.17: 6, 0.32: 5}}, 0.43: 5, 0.45: 6, 0.48: 6, 0.5: 6, 0.52: 5, 0.57: 5, 0.58: 6, 0.59: {2: {0.05: 5, 0.16: 7}}, 0.6: 5, 0.62: {2: {0.33: 6, 0.35: 5}}, 0.64: 5, 0.67: 6, 0.705: 6, 0.71: 5, 0.715: 6, 0.725: 6, 0.745: 5, 0.77: 6, 0.81: 5, 0.83: 4, 1.18: 5}}, 8.1: {1: {0.29: 7, 0.33: 5, 0.38: {2: {0.28: 7, 0.48: 5}}, 0.53: 6, 0.545: 6, 0.56: 5, 0.575: 5, 0.66: 5, 0.67: 5, 0.72: 6, 0.725: 5, 0.73: 4, 0.78: 5, 0.785: 5, 0.82: 5, 0.825: 6, 0.87: {2: {0.0: {3: {2.2: 5, 3.3: 4}}}}, 1.33: 5}}, 8.2: {1: {0.2: 6, 0.23: 6, 0.24: 6, 0.26: 7, 0.28: {2: {0.4: 7, 0.6: 5}}, 0.31: 7, 0.32: 6, 0.33: 7, 0.34: 6, 0.35: 6, 0.38: 6, 0.39: 5, 0.4: 6, 0.42: 6, 0.43: 5, 0.44: 6, 0.5: 5, 0.51: 6, 0.56: 5, 0.57: 5, 0.59: 6, 0.6: 5, 0.635: 6, 0.64: 6, 0.7: 5, 0.73: 5, 0.74: 6, 0.78: 4, 0.885: 5, 0.915: 4, 1.0: 6, 1.33: 5}}, 8.3: {1: {0.26: 6, 0.28: 7, 0.3: 7, 0.31: 7, 0.33: 7, 0.34: 6, 0.42: 6, 0.43: 5, 0.49: 6, 0.53: 6, 0.54: {2: {0.24: 5, 0.28: 6}}, 0.56: 5, 0.58: 6, 0.6: {2: {0.13: 6, 0.25: 5}}, 0.61: 6, 0.615: 5, 0.625: 4, 0.65: 5, 0.655: 5, 0.66: 6, 0.675: 4, 0.705: 5, 0.715: 5, 0.76: 6, 0.78: 5, 0.845: 4, 0.85: 5, 1.02: 3}}, 8.4: {1: {0.25: 7, 0.29: 5, 0.31: 6, 0.34: 6, 0.36: 6, 0.37: {2: {0.43: 7, 0.53: 6}}, 0.39: 6, 0.52: 6, 0.56: 5, 0.59: 5, 0.6: 5, 0.62: {2: {0.09: 5, 0.12: 6}}, 0.635: 4, 0.65: 5, 0.665: 5, 0.67: 4, 0.715: 5, 0.745: 5, 1.035: 5}}, 8.5: {1: {0.18: 7, 0.21: 5, 0.28: 7, 0.32: 7, 0.34: {2: {0.4: 7, 0.44: 5}}, 0.37: 6, 0.4: 4, 0.44: 5, 0.46: 5, 0.47: 6, 0.49: 5, 0.585: 6, 0.655: 5, 0.66: 5}}, 8.6: {1: {0.22: 7, 0.315: 6, 0.33: 5, 0.37: 5, 0.38: 5, 0.42: 8, 0.45: 6, 0.47: 5, 0.49: {2: {0.28: 6, 0.29: 5, 0.51: 5}}, 0.52: 5, 0.53: 6, 0.55: 5, 0.63: 5, 0.635: 5, 0.645: 6, 0.685: 6, 0.725: 5, 0.8: 5, 0.83: 6}}, 8.7: {1: {0.29: 5, 0.31: 6, 0.33: 7, 0.41: 7, 0.42: 6, 0.46: 5, 0.48: 7, 0.52: 7, 0.54: 6, 0.625: 5, 0.63: 6, 0.675: 5, 0.69: {2: {0.0: 5, 0.31: 6}}, 0.7: 6, 0.765: 5, 0.78: 5, 0.82: 5, 0.84: 5}}, 8.8: {1: {0.24: {2: {0.35: 7, 0.54: 5}}, 0.27: 6, 0.3: 6, 0.31: 7, 0.33: 7, 0.37: 5, 0.4: 5, 0.41: 5, 0.42: 5, 0.44: 5, 0.45: 6, 0.46: 6, 0.47: 5, 0.48: 6, 0.52: 5, 0.55: 6, 0.59: 5, 0.6: 5, 0.61: {2: {0.14: 5, 0.19: 6, 0.3: 4}}, 0.64: 5, 0.66: 5, 0.685: 5, 0.7: 6, 0.955: 4}}, 8.9: {1: {0.12: 7, 0.22: 6, 0.24: 6, 0.28: 7, 0.29: 6, 0.31: 5, 0.32: 6, 0.35: 7, 0.38: 7, 0.4: 7, 0.43: 6, 0.48: {2: {0.24: 5, 0.53: 7}}, 0.5: 6, 0.565: 5, 0.59: {2: {0.39: 5, 0.5: 6}}, 0.595: 5, 0.61: 5, 0.62: 5, 0.635: 5, 0.745: 6, 0.75: 5, 0.84: 6, 0.875: 5}}, 9.0: {1: {0.36: 6, 0.38: 7, 0.39: 6, 0.4: 6, 0.43: 6, 0.44: 5, 0.45: 5, 0.46: {2: {0.23: 5, 0.31: 6}}, 0.47: 5, 0.48: 5, 0.53: 6, 0.54: 5, 0.58: 5, 0.6: 5, 0.62: 5, 0.66: 5, 0.69: 5, 0.785: 5, 0.8: 6, 0.82: 5}}, 9.1: {1: {0.21: 7, 0.22: 6, 0.25: 7, 0.28: 6, 0.29: 7, 0.3: 7, 0.34: 5, 0.36: 7, 0.37: 6, 0.4: {2: {0.5: 8, 0.57: 6}}, 0.45: 5, 0.47: 5, 0.5: 6, 0.52: 5, 0.6: 6, 0.64: 5, 0.66: 5, 0.68: 6, 0.76: 6, 0.765: 4, 0.775: 5, 0.785: 6, 0.795: 6}}, 9.2: {1: {0.31: 7, 0.36: 6, 0.41: 7, 0.43: {2: {0.49: 5, 0.52: 6}}, 0.46: 5, 0.52: 4, 0.53: 5, 0.54: 5, 0.56: 5, 0.58: 5, 0.59: 5, 0.63: 5, 0.67: 6, 0.755: 6, 0.92: 5}}, 9.3: {1: {0.27: 5, 0.32: 5, 0.33: 7, 0.36: 6, 0.37: 7, 0.38: 6, 0.39: {2: {0.4: 6, 0.44: 5}}, 0.4: 5, 0.41: 5, 0.43: 5, 0.48: 5, 0.49: 6, 0.5: 6, 0.61: 5, 0.655: 5, 0.715: 5, 0.775: 6}}, 9.4: {1: {0.24: 6, 0.27: 7, 0.3: 8, 0.33: 6, 0.34: 5, 0.395: 7, 0.4: {2: {0.31: 6, 0.47: 5}}, 0.41: 7, 0.43: 6, 0.5: 6, 0.59: 5, 0.615: 5, 0.685: {2: {0.11: 6, 0.26: 5}}}}, 9.5: {1: {0.37: {2: {0.52: {3: {2.0: {4: {0.082: 5, 0.088: 6}}}}}}, 0.39: 7, 0.46: 6, 0.55: 5, 0.56: 7, 0.57: 5, 0.59: 5, 0.735: 6, 0.78: 6, 0.86: 5, 0.885: 5}}, 9.6: {1: {0.32: 7, 0.33: 7, 0.38: {2: {0.31: 7, 0.42: 6}}, 0.41: 5, 0.42: 6, 0.5: 5, 0.54: 6, 0.56: {2: {0.23: 5, 0.31: 6}}, 0.6: 5, 0.68: 5, 0.77: 6, 0.88: 5}}, 9.7: {1: {0.295: 6, 0.31: 6, 0.32: 5, 0.42: 6, 0.53: 6, 0.55: 5, 0.66: 5, 0.69: 5}}, 9.8: {1: {0.25: 6, 0.3: 7, 0.34: 7, 0.37: 5, 0.39: 5, 0.44: 6, 0.45: 5, 0.5: {2: {0.34: 7, 0.49: 6}}, 0.51: 6, 0.66: 7, 0.88: 5, 0.98: 5, 1.24: 5}}, 9.9: {1: {0.25: 6, 0.27: 7, 0.32: 6, 0.35: {2: {0.38: 7, 0.41: 5, 0.55: 5}}, 0.4: 7, 0.44: 6, 0.49: 5, 0.5: {2: {0.24: 4, 0.5: 5}}, 0.53: 7, 0.54: 5, 0.57: 5, 0.59: 5, 0.63: 5, 0.72: 5, 0.74: 5}}, 10.0: {1: {0.26: 8, 0.29: 5, 0.31: 7, 0.32: 5, 0.35: {2: {0.45: 5, 0.47: 6}}, 0.38: 5, 0.41: 7, 0.42: 6, 0.43: 5, 0.44: 7, 0.46: 6, 0.48: 6, 0.49: 6, 0.56: 6, 0.58: 5, 0.59: 6, 0.69: 5, 0.73: 5}}, 10.1: {1: {0.27: 6, 0.28: 6, 0.31: {2: {0.35: 7, 0.44: 6}}, 0.37: 7, 0.38: 7, 0.43: 7, 0.45: 6, 0.65: 6, 0.935: 4}}, 10.2: {1: {0.23: 4, 0.24: 5, 0.29: {2: {0.49: 7, 0.65: 6}}, 0.33: 6, 0.34: 7, 0.36: 6, 0.4: 6, 0.41: 5, 0.42: 5, 0.44: 7, 0.49: 7, 0.54: 6, 0.645: 6, 0.67: 5}}, 10.3: {1: {0.27: 6, 0.32: 8, 0.34: 5, 0.41: 6, 0.43: 6, 0.44: 5, 0.5: 6, 0.53: 6, 0.59: 6}}, 10.4: {1: {0.24: {2: {0.46: 7, 0.49: 6}}, 0.26: 6, 0.28: 5, 0.33: 7, 0.34: 6, 0.38: 7, 0.41: 6, 0.43: 6, 0.44: {2: {0.42: 3, 0.73: 7}}, 0.52: 6, 0.55: 6, 0.575: 5, 0.61: 3, 0.64: 5}}, 10.5: {1: {0.24: 7, 0.26: 7, 0.28: 6, 0.36: 6, 0.39: 6, 0.42: 7, 0.43: 6, 0.51: 7, 0.59: 4}}, 10.6: {1: {0.28: 5, 0.31: 6, 0.34: 6, 0.36: {2: {0.57: 7, 0.59: 5, 0.6: 5}}, 0.42: 6, 0.44: 6, 0.48: 6, 0.5: 6, 0.83: 5, 1.02: 6, 1.025: 5}}, 10.7: {1: {0.35: 8, 0.4: 6, 0.43: 5, 0.46: 5, 0.52: 7, 0.67: 6, 0.9: 5}}, 10.8: {1: {0.26: 5, 0.29: 6, 0.32: 6, 0.4: 6, 0.45: 5, 0.47: 6, 0.5: 5, 0.89: 5}}, 10.9: {1: {0.21: 6, 0.32: 6, 0.37: 5, 0.39: 6, 0.53: 6}}, 11.0: {1: {0.2: 5, 0.26: 5, 0.3: 7}}, 11.1: {1: {0.18: 6, 0.31: 7, 0.35: 5, 0.39: 5, 0.42: 7, 0.44: 6, 0.45: 6}}, 11.2: {1: {0.28: 6, 0.4: 5, 0.5: 5, 0.66: 6, 0.67: 6}}, 11.3: {1: {0.34: 6, 0.36: 6, 0.37: 5, 0.62: 8}}, 11.4: {1: {0.26: 6, 0.36: 6, 0.46: 5, 0.6: 6, 0.625: 6}}, 11.5: {1: {0.18: 6, 0.3: 6, 0.31: 6, 0.315: 6, 0.35: 6, 0.41: 5, 0.42: 5, 0.45: 6, 0.54: 7, 0.59: 6}}, 11.6: {1: {0.23: 6, 0.32: 7, 0.41: {2: {0.54: 7, 0.58: 5}}, 0.42: 5, 0.44: 6, 0.47: 4, 0.475: 6, 0.53: 7, 0.58: 3}}, 11.7: {1: {0.28: 7, 0.45: 6, 0.49: 5}}, 11.8: {1: {0.26: 7, 0.33: 7, 0.38: 6}}, 11.9: {1: {0.37: 6, 0.38: {2: {0.49: 5, 0.51: 6}}, 0.39: 6, 0.4: 6, 0.43: 7, 0.57: 6, 0.58: {2: {0.58: 6, 0.66: 5}}, 0.695: 7}}, 12.0: {1: {0.28: 7, 0.37: 7, 0.38: 6, 0.39: 7, 0.45: 6, 0.5: 7, 0.63: 4}}, 12.1: 5, 12.2: {1: {0.34: 6, 0.45: 5, 0.48: 6}}, 12.3: {1: {0.27: 6, 0.39: 5, 0.5: 5}}, 12.4: {1: {0.35: 6, 0.4: 6, 0.42: 5, 0.49: 6}}, 12.5: {1: {0.28: 7, 0.37: 6, 0.38: 5, 0.46: {2: {0.49: 4, 0.63: 5}}, 0.56: 5, 0.6: 6}}, 12.6: {1: {0.31: 8, 0.38: 6, 0.39: 6, 0.41: 6}}, 12.7: {1: {0.59: 6, 0.6: 5}}, 12.8: {1: {0.3: 7, 0.615: 7, 0.84: 6}}, 12.9: {1: {0.35: 7, 0.5: 6}}, 13.0: {1: {0.32: 5, 0.47: 6}}, 13.2: {1: {0.38: 5, 0.46: 6}}, 13.3: {1: {0.29: 7, 0.34: 6, 0.43: 5}}, 13.4: 6, 13.5: 5, 13.7: 6, 13.8: 6, 14.0: 6, 14.3: 6, 15.0: 7, 15.5: 5, 15.6: {1: {0.645: 5, 0.685: 7}}, 15.9: 5}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tree, X):\n",
        "    if not isinstance(tree, dict):\n",
        "        return tree\n",
        "\n",
        "    feature_index = next(iter(tree))\n",
        "    feature_value = X[feature_index]\n",
        "\n",
        "    if feature_value in tree[feature_index]:\n",
        "        return predict(tree[feature_index][feature_value], X)\n",
        "    else:\n",
        "        values = []\n",
        "        for sub_tree in tree[feature_index].values():\n",
        "            result = predict(sub_tree, X)\n",
        "            if isinstance(result, (list, tuple)):\n",
        "                values.extend(result)\n",
        "            else:\n",
        "                values.append(result)\n",
        "\n",
        "        from collections import Counter\n",
        "        return Counter(values).most_common(1)[0][0]\n",
        "\n",
        "def predict_all(tree, X):\n",
        "    return np.array([predict(tree, x) for x in X])\n"
      ],
      "metadata": {
        "id": "NRzIFQ1SF3yr"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "NyzHlxAWGDka"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = id3(X_train, y_train, feature_indices)"
      ],
      "metadata": {
        "id": "qz7cYYeqGMQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4148eb9c-348c-4217-9516-d9bb17756458"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-07167b9b838a>:5: RuntimeWarning: divide by zero encountered in log2\n",
            "  return -np.sum(p*np.log2(p))\n",
            "<ipython-input-6-07167b9b838a>:5: RuntimeWarning: invalid value encountered in multiply\n",
            "  return -np.sum(p*np.log2(p))\n",
            "<ipython-input-33-d423d8b12dd8>:5: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  weighted_avg_entropy = np.sum((count[i] / np.sum(count)) * entropy(y[X[:, feature_index] == values[i]]) for i in range(len(values)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict_all(tree, X_test)\n"
      ],
      "metadata": {
        "id": "AatkuRARQpZd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qlgU9rGQvg-",
        "outputId": "7cf5e56f-7315-402b-a3bb-e6a0bf7fe83c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5270833333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BBG4A5_YQyHN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}